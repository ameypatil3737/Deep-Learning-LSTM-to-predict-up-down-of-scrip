{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0004fd8",
   "metadata": {
    "id": "a0004fd8"
   },
   "source": [
    "# AMEY ANANT PATIL\n",
    "\n",
    "### Reddit BTC Sentiments\n",
    "\n",
    "A 5KK database of Reddit Commentaries from Big Query is processed and the sentiments polarities are calculated with VADER and the aggregated per day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a8d3e5",
   "metadata": {
    "id": "d3a8d3e5"
   },
   "source": [
    "***\n",
    "## Necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09582863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swifter in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from swifter) (4.64.1)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from swifter) (5.9.0)\n",
      "Requirement already satisfied: dask[dataframe]>=2.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from swifter) (2022.7.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from swifter) (2.0.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.2.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2022.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (22.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.23.5)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.33.0->swifter) (0.4.6)\n",
      "Requirement already satisfied: locket in c:\\programdata\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install swifter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724a7c5a",
   "metadata": {
    "id": "724a7c5a"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd # usaremos o pandas com processamento paralelo do modin\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import unicodedata\n",
    "import plotly.express as px\n",
    "import re\n",
    "import string\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419bbdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\NATHDWAR\\\\Desktop\\\\Fitch Python\\\\Final project\\\\CQF_final_project-main'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e19b97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    reddit = pd.DataFrame()\n",
    "    reddit = pd.read_csv('part_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729acde2",
   "metadata": {
    "id": "729acde2"
   },
   "source": [
    "***\n",
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b8f9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\NATHDWAR\\\\Desktop\\\\Fitch Python\\\\Final project\\\\CQF_final_project-main'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef49b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Training Fast Text in a example database:\n",
    "model = fasttext.load_model('lid.176.ftz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e413657a",
   "metadata": {
    "id": "e413657a",
    "outputId": "dcaed3cd-aa61-4f54-e937-e2e0ec6e1883"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Fast Text is a Facebook NLP lib.\n",
    "\n",
    "\n",
    "# Training Fast Text in a example database:\n",
    "model = fasttext.load_model('lid.176.ftz')\n",
    "\n",
    "# Function to identify language (VADER only works for english):\n",
    "\n",
    "def fast_detect(msg):\n",
    "    try:\n",
    "        # The following predict returns the text language\n",
    "        ln = model.predict(msg)[0][0].split(\"__\")[2] \n",
    "    except:\n",
    "        # It defaults to None when it fails\n",
    "        ln = None\n",
    "    return ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71ffe3c",
   "metadata": {
    "id": "c71ffe3c"
   },
   "outputs": [],
   "source": [
    "# Function to remove special characters from comments\n",
    "def convert_text(text):\n",
    "    \n",
    "    text = re.sub(r'\\s+', ' ',str(text))\n",
    "    \n",
    "    \n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    text = text.replace(\"\\\\'\",\"'\")\n",
    "    text = text.replace('\\\\','')\n",
    "    \n",
    "    text = text.replace('*','')\n",
    "    text = text.replace('_','')\n",
    "\n",
    "    \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5cd8d7",
   "metadata": {
    "id": "4d5cd8d7"
   },
   "outputs": [],
   "source": [
    "# Function to use VADER:\n",
    "def VADER(text):\n",
    "    \n",
    "    sent_an = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    \n",
    "    sentiment_dict = sent_an.polarity_scores(text)\n",
    "\n",
    "    # only the compound polarity score is used:\n",
    "    return sentiment_dict['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd65d2e",
   "metadata": {
    "id": "ddd65d2e"
   },
   "source": [
    "***\n",
    "## Importing downloaded data\n",
    "\n",
    "As the query retrieved a huge dataset, BigQuery partitioned it into multiple files to export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf44493",
   "metadata": {
    "id": "9cf44493",
    "outputId": "e1843e7d-6629-438e-b986-3fb6a6ced807"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\3791039482.py:3: DtypeWarning: Columns (0,1,2,3,4,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitcoin_reddit_all.csv (4309244, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\3791039482.py:3: DtypeWarning: Columns (0,1,2,3,4,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitcoin_reddit_all.csv.zip (4309244, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reddit = pd.DataFrame()\n",
    "for file in glob.glob('bitcoin_reddit_all*'):\n",
    "    df = pd.read_csv(file)\n",
    "    print(file,df.shape)\n",
    "    reddit=reddit.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd22a9",
   "metadata": {
    "id": "39cd22a9"
   },
   "source": [
    "Checking the file size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ddee05f",
   "metadata": {
    "id": "2ddee05f",
    "outputId": "5277d7a7-8040-49b8-8c00-ed2d65024040"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8618488, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape #8618488"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2d3f3",
   "metadata": {
    "id": "ebe2d3f3"
   },
   "source": [
    "The dataset comprises 8,618,488 commentaries mentioning either bitcoin or btc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7cc4da7",
   "metadata": {
    "id": "a7cc4da7",
    "outputId": "13f26341-0ed3-4404-8a2a-00e8a3675762",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2767174</th>\n",
       "      <td>2651295</td>\n",
       "      <td>2017-07-29 10:54:18</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>maroule</td>\n",
       "      <td>Ripple</td>\n",
       "      <td>1.501326e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Honestly, I have a hard time finding something...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0             datetime        date   author subreddit  \\\n",
       "2767174    2651295  2017-07-29 10:54:18  2017-07-29  maroule    Ripple   \n",
       "\n",
       "          created_utc  score  controversiality  \\\n",
       "2767174  1.501326e+09    2.0               0.0   \n",
       "\n",
       "                                                      body  \n",
       "2767174  Honestly, I have a hard time finding something...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.sample(1)\n",
    "#reddit.sample(min(3, len(reddit)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fac867",
   "metadata": {
    "id": "b5fac867"
   },
   "source": [
    "The table returned is structured as follows:\n",
    "\n",
    "* subreddit\n",
    "\n",
    "* UTC created date\n",
    "\n",
    "* commentary body of text\n",
    "\n",
    "* score = upvotes - downvotes (liquid score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2007426",
   "metadata": {
    "id": "c2007426"
   },
   "source": [
    "***\n",
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e5ef06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'datetime', 'date', 'author', 'subreddit', 'created_utc',\n",
      "       'score', 'controversiality', 'body'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(reddit.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02ca8c78",
   "metadata": {
    "id": "02ca8c78"
   },
   "outputs": [],
   "source": [
    "# Converting from unix to UTC\n",
    "\n",
    "reddit['Created Date'] = pd.to_datetime(reddit['created_utc'],unit = 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4790ee42",
   "metadata": {
    "id": "4790ee42"
   },
   "outputs": [],
   "source": [
    "# Ordering by created date\n",
    "\n",
    "reddit.sort_values('Created Date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775efcf",
   "metadata": {
    "id": "5775efcf"
   },
   "source": [
    "We use the previously defined function to remove special characters.\n",
    "\n",
    "Due to the dataset size, **Swifter** was used for parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63fdc4ad",
   "metadata": {
    "id": "63fdc4ad",
    "outputId": "d847a8aa-0738-4496-ce9f-07b451536f44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>body</th>\n",
       "      <th>Created Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124711</th>\n",
       "      <td>124689</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>maurice</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241791e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124711</th>\n",
       "      <td>124689</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>maurice</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241791e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136797</th>\n",
       "      <td>136769</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>badassumption</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241793e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136797</th>\n",
       "      <td>136769</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>badassumption</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241793e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167844</th>\n",
       "      <td>167813</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>Enginerd</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241801e+09</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&amp;gt;a public list of all the previous transact...</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             datetime        date         author subreddit  \\\n",
       "124711     124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "124711     124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "136797     136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "136797     136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "167844     167813  2009-05-08 16:35:36  2009-05-08       Enginerd  business   \n",
       "\n",
       "         created_utc  score  controversiality  \\\n",
       "124711  1.241791e+09    1.0               0.0   \n",
       "124711  1.241791e+09    1.0               0.0   \n",
       "136797  1.241793e+09    2.0               0.0   \n",
       "136797  1.241793e+09    2.0               0.0   \n",
       "167844  1.241801e+09   -3.0               0.0   \n",
       "\n",
       "                                                     body        Created Date  \n",
       "124711  Interesting, it uses IRC as a high level proto... 2009-05-08 13:54:29  \n",
       "124711  Interesting, it uses IRC as a high level proto... 2009-05-08 13:54:29  \n",
       "136797  No - the richest person will be the one with t... 2009-05-08 14:29:56  \n",
       "136797  No - the richest person will be the one with t... 2009-05-08 14:29:56  \n",
       "167844  &gt;a public list of all the previous transact... 2009-05-08 16:35:36  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f40ec",
   "metadata": {},
   "source": [
    "After removing special characters, the body language is classified with Fast Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d63141a",
   "metadata": {
    "id": "7d63141a",
    "outputId": "05acb68b-7a1b-407b-be0c-561c52136a19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\swifter\\swifter.py:87: UserWarning: This pandas object has duplicate indices, and swifter may not be able to improve performance. Consider resetting the indices with `df.reset_index(drop=True)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ed0f45956a4a7fb18f5e679cd2d528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8618488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\swifter\\swifter.py:87: UserWarning: This pandas object has duplicate indices, and swifter may not be able to improve performance. Consider resetting the indices with `df.reset_index(drop=True)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545ec0980bbb4383bd7a061b53343edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8618488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Removing special characters\n",
    "reddit['Comment'] = reddit['body'].swifter.apply(convert_text)\n",
    "\n",
    "\n",
    "# Infering language\n",
    "reddit['Language'] = reddit['Comment'].swifter.apply(fast_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4a6a7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Unnamed: 0             datetime        date         author subreddit  \\\n",
       "124711      124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "124711      124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "136797      136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "136797      136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "167844      167813  2009-05-08 16:35:36  2009-05-08       Enginerd  business   \n",
       "...            ...                  ...         ...            ...       ...   \n",
       "3827061    3711178  2019-12-31 23:57:54  2019-12-31       femstora     4chan   \n",
       "4231225    4115341  2019-12-31 23:58:07  2019-12-31   Benjamincito   Bitcoin   \n",
       "4231225    4115341  2019-12-31 23:58:07  2019-12-31   Benjamincito   Bitcoin   \n",
       "4256552    4140668  2019-12-31 23:58:38  2019-12-31  Skullpopper69  Buttcoin   \n",
       "4256552    4140668  2019-12-31 23:58:38  2019-12-31  Skullpopper69  Buttcoin   \n",
       "\n",
       "          created_utc  score  controversiality  \\\n",
       "124711   1.241791e+09    1.0               0.0   \n",
       "124711   1.241791e+09    1.0               0.0   \n",
       "136797   1.241793e+09    2.0               0.0   \n",
       "136797   1.241793e+09    2.0               0.0   \n",
       "167844   1.241801e+09   -3.0               0.0   \n",
       "...               ...    ...               ...   \n",
       "3827061  1.577837e+09   23.0               0.0   \n",
       "4231225  1.577837e+09    6.0               0.0   \n",
       "4231225  1.577837e+09    6.0               0.0   \n",
       "4256552  1.577837e+09    8.0               0.0   \n",
       "4256552  1.577837e+09    8.0               0.0   \n",
       "\n",
       "                                                      body  \\\n",
       "124711   Interesting, it uses IRC as a high level proto...   \n",
       "124711   Interesting, it uses IRC as a high level proto...   \n",
       "136797   No - the richest person will be the one with t...   \n",
       "136797   No - the richest person will be the one with t...   \n",
       "167844   &gt;a public list of all the previous transact...   \n",
       "...                                                    ...   \n",
       "3827061  Or back to the future it and go bet money on a...   \n",
       "4231225  People arent selling\\n\\nThey are just withdraw...   \n",
       "4231225  People arent selling\\n\\nThey are just withdraw...   \n",
       "4256552  Jorge!! Long-time no see you handsome bastard!...   \n",
       "4256552  Jorge!! Long-time no see you handsome bastard!...   \n",
       "\n",
       "               Created Date  \\\n",
       "124711  2009-05-08 13:54:29   \n",
       "124711  2009-05-08 13:54:29   \n",
       "136797  2009-05-08 14:29:56   \n",
       "136797  2009-05-08 14:29:56   \n",
       "167844  2009-05-08 16:35:36   \n",
       "...                     ...   \n",
       "3827061 2019-12-31 23:57:54   \n",
       "4231225 2019-12-31 23:58:07   \n",
       "4231225 2019-12-31 23:58:07   \n",
       "4256552 2019-12-31 23:58:38   \n",
       "4256552 2019-12-31 23:58:38   \n",
       "\n",
       "                                                   Comment Language  \n",
       "124711   Interesting, it uses IRC as a high level proto...       en  \n",
       "124711   Interesting, it uses IRC as a high level proto...       en  \n",
       "136797   No - the richest person will be the one with t...       en  \n",
       "136797   No - the richest person will be the one with t...       en  \n",
       "167844   &gt;a public list of all the previous transact...       en  \n",
       "...                                                    ...      ...  \n",
       "3827061  Or back to the future it and go bet money on a...       en  \n",
       "4231225  People arent selling They are just withdrawing...       en  \n",
       "4231225  People arent selling They are just withdrawing...       en  \n",
       "4256552  Jorge!! Long-time no see you handsome bastard!...       en  \n",
       "4256552  Jorge!! Long-time no see you handsome bastard!...       en  \n",
       "\n",
       "[8404402 rows x 12 columns]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c2f3b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.to_csv('part_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abf5f129",
   "metadata": {
    "id": "abf5f129",
    "outputId": "a479d3a1-daf0-47df-ed4f-28eacceed914"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contagem</th>\n",
       "      <td>8404402</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          english  others\n",
       "contagem  8404402     0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Languages\n",
    "cont = reddit['Language'].value_counts().to_frame('contagem')\n",
    "cont2 = pd.DataFrame({'english':cont.loc['en'], 'others':cont.iloc[1:].sum(axis=0)})\n",
    "cont2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d67844",
   "metadata": {
    "id": "f4d67844"
   },
   "source": [
    "As VADER only works for english text, the other languages are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cf3219a",
   "metadata": {
    "id": "0cf3219a"
   },
   "outputs": [],
   "source": [
    "reddit.query('Language == \"en\"',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02738db8",
   "metadata": {
    "id": "02738db8"
   },
   "source": [
    "VADER is then used to obtain the compound sentiment polarity score for each comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04b93eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\NATHDWAR\\AppData\\Roaming\\nltk_data...\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
      "C:\\Users\\NATHDWAR\\AppData\\Local\\Temp\\ipykernel_10580\\4063223723.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All threads have finished processing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import threading\n",
    "\n",
    "# Download the VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer after downloading the lexicon\n",
    "VADER = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to process a chunk and save it to CSV\n",
    "def process_chunk(chunk, index):\n",
    "    chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
    "    chunk.to_csv(f'bup{index}.csv', index=False)\n",
    "\n",
    "# Assuming you have already loaded your Reddit data into the 'reddit' DataFrame\n",
    "\n",
    "# Calculate the chunk size (10% of total rows)\n",
    "chunk_size = len(reddit) // 10\n",
    "\n",
    "# Create and start threads for processing chunks\n",
    "threads = []\n",
    "for i in range(10):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = start_idx + chunk_size\n",
    "    \n",
    "    # Create a thread for each chunk\n",
    "    chunk = reddit.iloc[start_idx:end_idx]\n",
    "    thread = threading.Thread(target=process_chunk, args=(chunk, i))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"All threads have finished processing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e70ffc",
   "metadata": {},
   "source": [
    "#VADER = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculate the chunk size (10% of total rows)\n",
    "chunk_size = len(reddit) // 10\n",
    "\n",
    "# Process the data in chunks\n",
    "for i in range(10):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = start_idx + chunk_size\n",
    "    \n",
    "    # Process the current chunk using VADER\n",
    "    chunk = reddit.iloc[start_idx:end_idx]\n",
    "    chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
    "    \n",
    "    # Export the chunk to a CSV file\n",
    "    chunk.to_csv(f'bup{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9efe68",
   "metadata": {},
   "source": [
    "total_rows = len(reddit)\n",
    "chunk_size = ceil(total_rows / 10)\n",
    "\n",
    "# Process the data in chunks\n",
    "for i in tqdm(range(0, total_rows, chunk_size)):\n",
    "    chunk = reddit.iloc[i:i+chunk_size]\n",
    "    chunk['Sentiment'] = chunk['Comment'].apply(VADER.polarity_scores)\n",
    "    # Process chunk further if needed\n",
    "    \n",
    "    # For example, you can save the processed chunk back to your DataFrame\n",
    "    reddit.iloc[i:i+chunk_size] = chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e7a0a",
   "metadata": {
    "id": "0f9c045d",
    "outputId": "bfc4c444-698c-4fe3-8516-bb137a214e24"
   },
   "source": [
    "#Once again using swifter to accelearate processing:\n",
    "reddit['Sentiment'] = reddit['Comment'].swifter.apply(VADER,axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ecccc",
   "metadata": {
    "id": "aa8d8c47"
   },
   "source": [
    "reddit.to_csv('bup1.csv') #saving a backup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c2da8f",
   "metadata": {
    "id": "f4c2da8f"
   },
   "source": [
    "\n",
    "The scores are normalized with MinMaxScaler (there are negative scores) and used to weight the compound polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3011060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>body</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124689</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>maurice</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241791e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124689</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>maurice</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241791e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136769</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>badassumption</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241793e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136769</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>badassumption</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241793e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167813</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>Enginerd</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241801e+09</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&amp;gt;a public list of all the previous transact...</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "      <td>&amp;gt;a public list of all the previous transact...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.115, 'neu': 0.781, 'pos': 0.104, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             datetime        date         author subreddit  \\\n",
       "0      124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "1      124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "2      136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "3      136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "4      167813  2009-05-08 16:35:36  2009-05-08       Enginerd  business   \n",
       "\n",
       "    created_utc  score  controversiality  \\\n",
       "0  1.241791e+09    1.0               0.0   \n",
       "1  1.241791e+09    1.0               0.0   \n",
       "2  1.241793e+09    2.0               0.0   \n",
       "3  1.241793e+09    2.0               0.0   \n",
       "4  1.241801e+09   -3.0               0.0   \n",
       "\n",
       "                                                body         Created Date  \\\n",
       "0  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
       "1  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
       "2  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
       "3  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
       "4  &gt;a public list of all the previous transact...  2009-05-08 16:35:36   \n",
       "\n",
       "                                             Comment Language  \\\n",
       "0  Interesting, it uses IRC as a high level proto...       en   \n",
       "1  Interesting, it uses IRC as a high level proto...       en   \n",
       "2  No - the richest person will be the one with t...       en   \n",
       "3  No - the richest person will be the one with t...       en   \n",
       "4  &gt;a public list of all the previous transact...       en   \n",
       "\n",
       "                                           Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...  \n",
       "1  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...  \n",
       "2  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...  \n",
       "3  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...  \n",
       "4  {'neg': 0.115, 'neu': 0.781, 'pos': 0.104, 'co...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('bup0.csv')\n",
    "#reddit3=reddit3.append(df)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d0bcfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>body</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Compound_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124689</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>maurice</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241791e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124689</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>maurice</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241791e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136769</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>badassumption</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241793e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136769</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>badassumption</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241793e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167813</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>Enginerd</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241801e+09</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&amp;gt;a public list of all the previous transact...</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "      <td>&amp;gt;a public list of all the previous transact...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.115, 'neu': 0.781, 'pos': 0.104, 'co...</td>\n",
       "      <td>-0.0772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             datetime        date         author subreddit  \\\n",
       "0      124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "1      124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "2      136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "3      136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "4      167813  2009-05-08 16:35:36  2009-05-08       Enginerd  business   \n",
       "\n",
       "    created_utc  score  controversiality  \\\n",
       "0  1.241791e+09    1.0               0.0   \n",
       "1  1.241791e+09    1.0               0.0   \n",
       "2  1.241793e+09    2.0               0.0   \n",
       "3  1.241793e+09    2.0               0.0   \n",
       "4  1.241801e+09   -3.0               0.0   \n",
       "\n",
       "                                                body         Created Date  \\\n",
       "0  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
       "1  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
       "2  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
       "3  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
       "4  &gt;a public list of all the previous transact...  2009-05-08 16:35:36   \n",
       "\n",
       "                                             Comment Language  \\\n",
       "0  Interesting, it uses IRC as a high level proto...       en   \n",
       "1  Interesting, it uses IRC as a high level proto...       en   \n",
       "2  No - the richest person will be the one with t...       en   \n",
       "3  No - the richest person will be the one with t...       en   \n",
       "4  &gt;a public list of all the previous transact...       en   \n",
       "\n",
       "                                           Sentiment  Compound_Score  \n",
       "0  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...          0.4019  \n",
       "1  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...          0.4019  \n",
       "2  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...          0.5267  \n",
       "3  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...          0.5267  \n",
       "4  {'neg': 0.115, 'neu': 0.781, 'pos': 0.104, 'co...         -0.0772  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89add39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0             datetime        date         author subreddit  \\\n",
      "0      124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
      "1      124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
      "2      136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
      "3      136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
      "4      167813  2009-05-08 16:35:36  2009-05-08       Enginerd  business   \n",
      "\n",
      "    created_utc  score  controversiality  \\\n",
      "0  1.241791e+09    1.0               0.0   \n",
      "1  1.241791e+09    1.0               0.0   \n",
      "2  1.241793e+09    2.0               0.0   \n",
      "3  1.241793e+09    2.0               0.0   \n",
      "4  1.241801e+09   -3.0               0.0   \n",
      "\n",
      "                                                body         Created Date  \\\n",
      "0  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
      "1  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
      "2  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
      "3  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
      "4  &gt;a public list of all the previous transact...  2009-05-08 16:35:36   \n",
      "\n",
      "                                             Comment Language  \\\n",
      "0  Interesting, it uses IRC as a high level proto...       en   \n",
      "1  Interesting, it uses IRC as a high level proto...       en   \n",
      "2  No - the richest person will be the one with t...       en   \n",
      "3  No - the richest person will be the one with t...       en   \n",
      "4  &gt;a public list of all the previous transact...       en   \n",
      "\n",
      "                                           Sentiment  Compound_Score  \n",
      "0  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...          0.4019  \n",
      "1  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...          0.4019  \n",
      "2  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...          0.5267  \n",
      "3  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...          0.5267  \n",
      "4  {'neg': 0.115, 'neu': 0.781, 'pos': 0.104, 'co...         -0.0772  \n"
     ]
    }
   ],
   "source": [
    "def extract_compound_score(sentiment_dict_str):\n",
    "    compound_score_match = re.search(r\"'compound':\\s*(-?\\d+\\.\\d+)\", sentiment_dict_str)\n",
    "    if compound_score_match:\n",
    "        return float(compound_score_match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create a new column 'Compound_Score'\n",
    "df2['Compound_Score'] = (df2['Sentiment'].apply(extract_compound_score))\n",
    "#reddit1 = reddit1[['Compound_Score']]\n",
    "# Print the result\n",
    "print(df2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0c840b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, datetime, date, author, subreddit, created_utc, score, controversiality, body, Created Date, Comment, Language, Sentiment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "empty_columns = ['Unnamed: 0', 'datetime', 'date', 'author', 'subreddit', 'created_utc', 'score',\n",
    "                 'controversiality', 'body', 'Created Date', 'Comment', 'Language', 'Sentiment']\n",
    "empty_data = pd.DataFrame(columns=empty_columns)\n",
    "\n",
    "# Overwrite the 'reddit' DataFrame with the new empty DataFrame\n",
    "reddit = empty_data\n",
    "df3=empty_data\n",
    "# Print the empty DataFrame\n",
    "print(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6922dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bup0.csv (840440, 13)\n",
      "bup1.csv (840440, 13)\n",
      "bup2.csv (840440, 13)\n",
      "bup3.csv (840440, 13)\n",
      "bup4.csv (840440, 13)\n",
      "bup5.csv (840440, 13)\n",
      "bup6.csv (840440, 13)\n",
      "bup7.csv (840440, 13)\n",
      "bup8.csv (840440, 13)\n",
      "bup9.csv (840440, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in glob.glob('bup*'):\n",
    "    df3 = pd.read_csv(file)\n",
    "    print(file,df.shape)\n",
    "    reddit=reddit.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18a8be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>body</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124689</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>maurice</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241791e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124689</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>maurice</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241791e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136769</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>badassumption</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241793e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136769</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>badassumption</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241793e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167813</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "      <td>2009-05-08</td>\n",
       "      <td>Enginerd</td>\n",
       "      <td>business</td>\n",
       "      <td>1.241801e+09</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&amp;gt;a public list of all the previous transact...</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "      <td>&amp;gt;a public list of all the previous transact...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'neg': 0.115, 'neu': 0.781, 'pos': 0.104, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0             datetime        date         author subreddit  \\\n",
       "0     124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "1     124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
       "2     136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "3     136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
       "4     167813  2009-05-08 16:35:36  2009-05-08       Enginerd  business   \n",
       "\n",
       "    created_utc  score  controversiality  \\\n",
       "0  1.241791e+09    1.0               0.0   \n",
       "1  1.241791e+09    1.0               0.0   \n",
       "2  1.241793e+09    2.0               0.0   \n",
       "3  1.241793e+09    2.0               0.0   \n",
       "4  1.241801e+09   -3.0               0.0   \n",
       "\n",
       "                                                body         Created Date  \\\n",
       "0  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
       "1  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
       "2  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
       "3  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
       "4  &gt;a public list of all the previous transact...  2009-05-08 16:35:36   \n",
       "\n",
       "                                             Comment Language  \\\n",
       "0  Interesting, it uses IRC as a high level proto...       en   \n",
       "1  Interesting, it uses IRC as a high level proto...       en   \n",
       "2  No - the richest person will be the one with t...       en   \n",
       "3  No - the richest person will be the one with t...       en   \n",
       "4  &gt;a public list of all the previous transact...       en   \n",
       "\n",
       "                                           Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...  \n",
       "1  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...  \n",
       "2  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...  \n",
       "3  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...  \n",
       "4  {'neg': 0.115, 'neu': 0.781, 'pos': 0.104, 'co...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reddit2 = reddit\n",
    "reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f23993b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0             datetime        date         author subreddit  \\\n",
      "0     124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
      "1     124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
      "2     136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
      "3     136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
      "4     167813  2009-05-08 16:35:36  2009-05-08       Enginerd  business   \n",
      "\n",
      "    created_utc  score  controversiality  \\\n",
      "0  1.241791e+09    1.0               0.0   \n",
      "1  1.241791e+09    1.0               0.0   \n",
      "2  1.241793e+09    2.0               0.0   \n",
      "3  1.241793e+09    2.0               0.0   \n",
      "4  1.241801e+09   -3.0               0.0   \n",
      "\n",
      "                                                body         Created Date  \\\n",
      "0  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
      "1  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
      "2  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
      "3  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
      "4  &gt;a public list of all the previous transact...  2009-05-08 16:35:36   \n",
      "\n",
      "                                             Comment Language  \\\n",
      "0  Interesting, it uses IRC as a high level proto...       en   \n",
      "1  Interesting, it uses IRC as a high level proto...       en   \n",
      "2  No - the richest person will be the one with t...       en   \n",
      "3  No - the richest person will be the one with t...       en   \n",
      "4  &gt;a public list of all the previous transact...       en   \n",
      "\n",
      "                                           Sentiment  Compound_Score  \n",
      "0  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...          0.4019  \n",
      "1  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...          0.4019  \n",
      "2  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...          0.5267  \n",
      "3  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...          0.5267  \n",
      "4  {'neg': 0.115, 'neu': 0.781, 'pos': 0.104, 'co...         -0.0772  \n"
     ]
    }
   ],
   "source": [
    "def extract_compound_score(sentiment_dict_str):\n",
    "    compound_score_match = re.search(r\"'compound':\\s*(-?\\d+\\.\\d+)\", sentiment_dict_str)\n",
    "    if compound_score_match:\n",
    "        return float(compound_score_match.group(1))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create a new column 'Compound_Score'\n",
    "reddit['Compound_Score'] = (reddit['Sentiment'].apply(extract_compound_score))\n",
    "#reddit1 = reddit1[['Compound_Score']]\n",
    "# Print the result\n",
    "print(reddit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e5b8172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0             datetime        date         author subreddit  \\\n",
      "0     124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
      "1     124689  2009-05-08 13:54:29  2009-05-08        maurice  business   \n",
      "2     136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
      "3     136769  2009-05-08 14:29:56  2009-05-08  badassumption  business   \n",
      "4     167813  2009-05-08 16:35:36  2009-05-08       Enginerd  business   \n",
      "\n",
      "    created_utc  score  controversiality  \\\n",
      "0  1.241791e+09    1.0               0.0   \n",
      "1  1.241791e+09    1.0               0.0   \n",
      "2  1.241793e+09    2.0               0.0   \n",
      "3  1.241793e+09    2.0               0.0   \n",
      "4  1.241801e+09   -3.0               0.0   \n",
      "\n",
      "                                                body         Created Date  \\\n",
      "0  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
      "1  Interesting, it uses IRC as a high level proto...  2009-05-08 13:54:29   \n",
      "2  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
      "3  No - the richest person will be the one with t...  2009-05-08 14:29:56   \n",
      "4  &gt;a public list of all the previous transact...  2009-05-08 16:35:36   \n",
      "\n",
      "                                             Comment Language  \\\n",
      "0  Interesting, it uses IRC as a high level proto...       en   \n",
      "1  Interesting, it uses IRC as a high level proto...       en   \n",
      "2  No - the richest person will be the one with t...       en   \n",
      "3  No - the richest person will be the one with t...       en   \n",
      "4  &gt;a public list of all the previous transact...       en   \n",
      "\n",
      "                                       Sentiment_All  Sentiment  \n",
      "0  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...     0.4019  \n",
      "1  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...     0.4019  \n",
      "2  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...     0.5267  \n",
      "3  {'neg': 0.09, 'neu': 0.772, 'pos': 0.138, 'com...     0.5267  \n",
      "4  {'neg': 0.115, 'neu': 0.781, 'pos': 0.104, 'co...    -0.0772  \n"
     ]
    }
   ],
   "source": [
    "#reddit['Sentiment_All'] = reddit['Sentiment'].apply(lambda x: x['compound'])\n",
    "#reddit.rename(columns={'Sentiment': 'Sentiment_All'}, inplace=True)\n",
    "#reddit.rename(columns={'Compound_Score': 'Sentiment'}, inplace=True)\n",
    "print(reddit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0a21d7c1",
   "metadata": {
    "id": "0a21d7c1",
    "outputId": "cfa11196-462d-43b4-b07c-4566149ff810"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "      <td>&amp;gt;a public list of all the previous transact...</td>\n",
       "      <td>-0.0772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  score         Created Date  \\\n",
       "0  business    1.0  2009-05-08 13:54:29   \n",
       "1  business    1.0  2009-05-08 13:54:29   \n",
       "2  business    2.0  2009-05-08 14:29:56   \n",
       "3  business    2.0  2009-05-08 14:29:56   \n",
       "4  business   -3.0  2009-05-08 16:35:36   \n",
       "\n",
       "                                             Comment  Sentiment  \n",
       "0  Interesting, it uses IRC as a high level proto...     0.4019  \n",
       "1  Interesting, it uses IRC as a high level proto...     0.4019  \n",
       "2  No - the richest person will be the one with t...     0.5267  \n",
       "3  No - the richest person will be the one with t...     0.5267  \n",
       "4  &gt;a public list of all the previous transact...    -0.0772  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary Columns:\n",
    "reddit = reddit[['subreddit','score','Created Date','Comment','Sentiment']]\n",
    "reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a7240c9",
   "metadata": {
    "id": "8a7240c9",
    "outputId": "bd0b1a4f-2505-4f18-b306-80b773f6e53d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4256522"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.duplicated(keep='first').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c82ee",
   "metadata": {
    "id": "6c5c82ee"
   },
   "source": [
    "Removing the exact duplicated observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "249c2626",
   "metadata": {
    "id": "249c2626",
    "outputId": "2d78b3e8-4742-41cd-a5ba-8d15c8de4456"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4147878"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.drop_duplicates(inplace=True)\n",
    "reddit.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ba393",
   "metadata": {
    "id": "423ba393"
   },
   "source": [
    "The dataset goes from 8404402 to 4147878 observations after removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5cd623f",
   "metadata": {
    "id": "a5cd623f",
    "outputId": "1c233f4f-abfe-4467-e1b5-e618acb18b01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"amazon gift card free, amazon gift card codes free, amazon gift card 2017, amazon gift card hack, amazon gift card generator, amazon gift card giveaway, amazon gift card code generator, amazon gift card giveaway live, amazon gift card generator 2017, amazon gift card app, amazon gift card, amazon gift card code, amazon gift card balance, amazon gift card api, amazon gift card ad, amazon gift card adder, amazon gift card app hack, amazon gift card android, amazon gift card at best buy, amazon gift card and promotional codes, amazon gift card activator, amazon gift card already redeemed, a amazon gift card code, amazon gift card buy, amazon gift card box, amazon gift card barcode, amazon gift card balance mobile recharge, amazon gift card balance transfer to bank account, amazon gift card balance hack, amazon gift card balance transfer, amazon gift card bing rewards, amazon gift card best buy, amazon gift card code giveaway, amazon gift card codes 2017, amazon gift card codes 2017 no survey, amazon gift card code generator 2017, amazon gift card codes hack, amazon gift card code live, amazon gift card codes without human verification, amazon gift card deals, amazon gift card diwali, amazon gift card discount, amazon gift card delay, amazon gift card doesn't work, amazon gift card details, amazon gift card dollars to rupees, amazon gift card donation, amazon gift card deep web, amazon gift card dump, do amazon gift card generators work, do amazon gift cards work internationally, do amazon gift cards work worldwide, do amazon gift cards work on kindle, how do amazon gift cards work, amazon gift card email, amazon gift card explained, amazon gift card earn, amazon gift card exchange, amazon gift card exchange paypal, amazon gift card eligible items, amazon gift card expiry date, amazon gift card error, amazon gift card earning apps, amazon gift card expiry, amazon e gift card, amazon.com gift cards - e-mail delivery, amazon gift card free codes, amazon gift card for cash, amazon gift card fast, amazon gift card free 2017, amazon gift card free no survey, amazon gift card free hack, amazon gift card for bitcoin, amazon gift card free code 2017, amazon gift card free august 2017, amazon gift card game, amazon gift card glitch, amazon gift card giveaway legit, amazon gift card generator hack online, amazon gift card generator code, amazon gift card generator hack code, amazon gift card how to use, amazon gift card hack 2017, amazon gift card how to redeem, amazon gift card how to buy, amazon gift card hindi, amazon gift card how to send, amazon gift card hack working 2017, amazon gift card hack tool, amazon gift card how it works, amazon gift card india, amazon gift card india free, amazon gift card into cash, amazon gift card into paypal, amazon gift card international use, amazon gift card into bank account, amazon gift card instructions, amazon gift card into bitcoin, amazon gift card instant win, amazon gift card image, amazon gift card july 2017, amazon gift card jobs, amazon gift card jailbreak, free amazon gift card jailbreak, amazon gift card kya hota hai, amazon gift card kaise use kare, amazon gift card kaise paye, amazon gift card kya hai, amazon gift card kaise le, amazon gift card kaise jeete, amazon gift card kaise milta hai, amazon gift card kitkat, amazon kindle gift card, amazon gift card live, amazon gift card live giveaway, amazon gift card live stream, amazon gift card list, amazon gift card limit, amazon gift card list 2017, amazon gift card last 4 digits, amazon gift card legit, amazon gift card limca, amazon gift card loot, amazon gift card method, amazon gift card meme, amazon gift card money to paypal, amazon gift card multiple recipients, amazon gift card microsoft points, amazon gift card malayalam, amazon gift card mobile recharge, amazon gift card money transfer, amazon gift card meaning, amazon gift card maximum amount, amazon gift card number, amazon gift card no survey, amazon gift card not working, amazon gift card not working at checkout, amazon gift card no human verification, amazon gift card numbers that work, amazon gift card numbers free, amazon gift card number generator, amazon gift card not used, amazon gift card numbers 2017, amazon gift card offer, amazon gift card october 2017, amazon gift card online generator, amazon gift card offer $1000, amazon gift card on ebay, amazon gift card on sprite, amazon gift card on paytm, amazon gift card offer 2017, amazon gift card on limca, amazon gift card on yippee, amazon gift card purchase, amazon gift card paypal, amazon gift card print at home, amazon gift card problem, amazon gift card payment, amazon gift card pin, amazon gift card promotion code, amazon gift card print, amazon gift card promotion code 2017, amazon gift card paypal credit, amazon gift card redeem, amazon gift card review, amazon gift card rewards, amazon gift card reload, amazon gift card redeem code hack, amazon gift card redeem code, amazon gift card refund trick, amazon gift card redeem free, amazon gift card redeem code not working, amazon gift card redemption, amazon gift card scams, amazon gift card shopping, amazon gift card survey, amazon gift card social security number, amazon gift card scratch, amazon gift card scratch off, amazon gift card scraper download, amazon gift card scam $1000, amazon gift card survey 2017, amazon gift card software download, amazon gift card to cash, amazon gift card tutorial, amazon gift card transfer, amazon gift card to money, amazon gift card trick, amazon gift card tool .rar, amazon gift card to btc, amazon gift card transfer to bank account, amazon gift card to paypal, amazon gift card to bank, amazon gift card use, amazon gift card unboxing, amazon gift card uk, amazon gift card use hindi, amazon gift card unused codes, amazon gift card usa, amazon gift card use kaise kare, amazon gift card uk paypal, amazon gift card uk generator, amazon gift card using paytm, use amazon gift card, use amazon gift card without credit card, use amazon gift card on paypal, use amazon gift card balance on another account, use amazon gift card online, use amazon gift card to buy another gift card, use amazon gift card on ebay, how to use amazon gift card balance, how to use amazon gift card in india, how to use amazon gift card on phone, amazon gift card visa, amazon gift card video, amazon gift card voucher, amazon gift card voucher codes, amazon gift card validity, amazon gift card voucher code hack, amazon gift card voucher free, amazon gift card via email, amazon gift card voucher promotional codes, amazon gift card generator v4.0 2016, amazon gift card wont work, amazon gift card working, amazon gift card walmart, amazon gift card with money, amazon gift card without credit card, amazon gift card winner, amazon gift card where is the claim code, amazon gift card won't apply, amazon gift card western union, amazon gift card what can i buy, amazon gift card xender, amazon gift card xbox live, amazon gift card xbox, amazon gift card youtube, amazon gift card yippee, amazon gift card 100, amazon gift card 1000, amazon gift card 10, amazon gift card 100 dollars, amazon gift card 10 dollars, amazon gift card 1000 facebook, amazon gift card 100 rs, free $100 amazon gift card, 1000 dollar amazon gift card, free 1000 amazon gift card, amazon gift card 2017 free, amazon gift card 200, amazon gift card 20 dollars, amazon gift card 2000, amazon gift card 2016, free amazon gift card 2016, free amazon gift card codes 2016, amazon gift card generator 2016, amazon gift card codes 2016, amazon gift card 30, amazon gift card 500, amazon gift card 50 dollars, amazon gift card 500 rs, free $50 amazon gift card, $50 amazon gift card, free 500 amazon gift card, 5 dollar amazon gift card, amazon 50 rs gift card, $5 amazon gift card, free $5 amazon gift card, amazon gift card 7 eleven, amazon gift card 711\"]\n"
     ]
    }
   ],
   "source": [
    "# Checking vader performance:\n",
    "print(reddit.query('Sentiment==1').sample(1)['Comment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bde77bc",
   "metadata": {
    "id": "8bde77bc",
    "outputId": "f738ebaf-f22a-42e7-95de-7145ab9a243b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The following comment by throwaway34234234523 was [openly]( greylisted. The original comment can be found(in censored form) at this link: np.reddit.com/r/ CryptoCurrency/comments/7poep7/-/dsire5o?context=4 The original comment's content was as follows: --- &gt; XRP is cancer for cryptocurrencies. Im sure you dont know abour technical specs of ripple, but is the worst coin for crypto. If it turns in main one day (as bitcoin), they will decrease the price of all alts until they cost almost zero, creating new coins. &gt; &gt; &gt;  100% Premine (cant mine new coins) &gt;  60% Held for creators (control) &gt;  No staking / No minig (no rewards for normal users) &gt;  Private blockchain (control, sell personal data) &gt;  Centralized (they can shutdown XRP blockchain when they want and crash the parity alts) &gt;  50$ stucked in wallet (20 XRP) (staking without reward) &gt;  Bound to identity (control, sell personal data) &gt; &gt; &gt; DO NOT SUPPORT RIPPLE (XRP), IT WANTS TO KILL CRYPTO TRADING. &gt; &gt; ---------- &gt; &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for OP. &gt; Votes in this post have been manipulated for ...\"]\n"
     ]
    }
   ],
   "source": [
    "print(reddit.query('Sentiment==-1').sample(1)['Comment'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be7e31",
   "metadata": {
    "id": "f9be7e31"
   },
   "source": [
    "It is clear that the comments that scored either the maximum / minimum compound polarity (+1, -1) are spams.\n",
    "\n",
    "This happens because VADER considers upper and lower cases as intensity indicator. Considering that only a few observations had the maximum/minimum score (3 observations), they are removed.\n",
    "\n",
    "\n",
    "The other similar occurrences are controled by using the influence as weight (score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "add4f1f1",
   "metadata": {
    "id": "add4f1f1"
   },
   "outputs": [],
   "source": [
    "reddit.query('Sentiment !=-1 & Sentiment != 1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74657593",
   "metadata": {
    "id": "74657593"
   },
   "outputs": [],
   "source": [
    "# Normalizing scores between 0-1\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "reddit['score_norm'] = scaler.fit_transform(reddit['score'].values.reshape(-1, 1))\n",
    "\n",
    "# Normalized Scores * Compount Polarity\n",
    "\n",
    "reddit['Sentiment_weighted'] = reddit['Sentiment']*(reddit['score_norm'])\n",
    "\n",
    "# Thus, the weighted sentiment varies between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ae34109",
   "metadata": {
    "id": "4ae34109"
   },
   "outputs": [],
   "source": [
    "# Defining daily dates:\n",
    "reddit['Day'] = pd.to_datetime(reddit['Created Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fdb87776",
   "metadata": {
    "id": "fdb87776",
    "outputId": "52bfd8fa-e600-4657-ae13-24d7b33ecc01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>score_norm</th>\n",
       "      <th>Sentiment_weighted</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009-05-08 13:54:29</td>\n",
       "      <td>Interesting, it uses IRC as a high level proto...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.053031</td>\n",
       "      <td>0.021313</td>\n",
       "      <td>2009-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2009-05-08 14:29:56</td>\n",
       "      <td>No - the richest person will be the one with t...</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.053064</td>\n",
       "      <td>0.027949</td>\n",
       "      <td>2009-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2009-05-08 16:35:36</td>\n",
       "      <td>&amp;gt;a public list of all the previous transact...</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.052901</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>2009-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>business</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2009-05-08 19:35:24</td>\n",
       "      <td>No, that's not how bitcoin works, check out th...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.053064</td>\n",
       "      <td>-0.015707</td>\n",
       "      <td>2009-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>business</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-07-18 21:38:06</td>\n",
       "      <td>It's weird how Ron Paul gets money so incredib...</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.052999</td>\n",
       "      <td>0.026330</td>\n",
       "      <td>2009-07-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  score         Created Date  \\\n",
       "0  business    1.0  2009-05-08 13:54:29   \n",
       "2  business    2.0  2009-05-08 14:29:56   \n",
       "4  business   -3.0  2009-05-08 16:35:36   \n",
       "6  business    2.0  2009-05-08 19:35:24   \n",
       "8  business    0.0  2009-07-18 21:38:06   \n",
       "\n",
       "                                             Comment  Sentiment  score_norm  \\\n",
       "0  Interesting, it uses IRC as a high level proto...     0.4019    0.053031   \n",
       "2  No - the richest person will be the one with t...     0.5267    0.053064   \n",
       "4  &gt;a public list of all the previous transact...    -0.0772    0.052901   \n",
       "6  No, that's not how bitcoin works, check out th...    -0.2960    0.053064   \n",
       "8  It's weird how Ron Paul gets money so incredib...     0.4968    0.052999   \n",
       "\n",
       "   Sentiment_weighted         Day  \n",
       "0            0.021313  2009-05-08  \n",
       "2            0.027949  2009-05-08  \n",
       "4           -0.004084  2009-05-08  \n",
       "6           -0.015707  2009-05-08  \n",
       "8            0.026330  2009-07-18  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f5209",
   "metadata": {
    "id": "a22f5209"
   },
   "source": [
    "The dataset is exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c04c15b6",
   "metadata": {
    "id": "c04c15b6"
   },
   "outputs": [],
   "source": [
    "reddit.to_csv('reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c2e5416",
   "metadata": {
    "id": "3c2e5416",
    "outputId": "2297c829-6091-4c4e-b3cc-16abf73bea7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4147875, 8)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9bafe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tratamento_Reddit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f398dbcdcf34a47fe45f2d7ff1fd709b6eeca34cdbd81c90dfbc6c78a0ae972"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
